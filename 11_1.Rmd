---
title: "11_1"
author: "Adrian Goedeckemeyer"
date: "11/11/2016"
output: html_document
---

## Statistical Learning intro

Creating Data:

Devise a regression (prediction) decision problem. This will require you to generate fake data (using any software you wish) and write a few sentences to accompany the data explaining the context and the decision problem itself.
IMPORTANT INSTRUCTIONS
• Your dataset should contain 100 observations. You should retain a random sample of 50 observations for yourself (the training set), and you will provide the remainder (the test set) to your partner.
• Your data generating process should be some function (not necessarily an additive function) of 2-4 features. You may provide your partner with more than 4 features, but if you do then do not identify the red herring(s). One of the features you use must be called “treatment” and represent receipt of a treatment or intervention.
• E.g., your formula could be:
Outcomes = 20*Age + 50*(Education)^2 - 2*Gender + 4*treat*gender + 10*treat + treat/(log(income) + N(0, 10)…
and then you would give give your partner a dataframe with outcomes, age, education, gender, treat, and income.
• You do not have to ‘balance’ your features in any way, and in particular, you don’t have to balance them with respect to treatment assignment. For example, you can
• Your error term must be normally distributed with a mean of zero.
• Do not overthink this. The entire exercise should take you no more than 30 minutes. POST QUESTIONS ON SLACK!!!
• Upload your data in .csv (comma-delimited) format to the Internet (e.g., on your Google Drive) and make it shareable with anyone who has the link.
• Put (a) the link to your data and (b) your paragraph in a shareable Google Doc.
• Create one or more simple data visualization(s) showing essential aspects of the data you created. Have the dataviz ready for class, but do not share it with other students.
You will not work on any aspect of this pre-class work with the other person assigned to your group. However, you will be working with this person in class, and you will swap problems and data with this person after class.


```{r}

set.seed(100)
gender <- rbinom(100,1,.5)
age <- sample(18:80, 100, replace = TRUE, prob = rnorm(63, .5, .2))
education <- sample(6:20, 100, replace = TRUE, prob = rnorm(15, .5, .2))
treat <- rbinom(100,1,.5)
income <- rnorm(100, 2000, 500)
outcome <- age^2 + (income)*(gender+.5) + education^2/(treat+1) + rnorm(100, 0, 50)

adrian_data <- data.frame(gender, age, education, income, treat, outcome)
training <- adrian_data[1:50,]
test <- adrian_data[51:100,]
plot(adrian_data, col=treat+1)

plot(density(adrian_data$outcome[adrian_data$treat]))
lines(density(adrian_data$outcome[adrian_data$treat == 0]), col=2)
library(foreign)
write.csv(training, file="11_1_adrian_training.csv")
write.dta(training, file="11_1_adrian_training.dta")
write.csv(test, file="11_1_adrian_test.csv")
write.dta(test, file="11_1_adrian_test.dta")
write.csv(adrian_data, file="11_1_adrian.csv")
write.dta(adrian_data, file="11_1_adrian.dta")

```

## Test RSME and R^2 for true model 

```{r}
res <- sum((test$outcome - test$age^2 + (test$income)*(test$gender+.5) + test$education^2/(test$treat+1))^2 )
rsme.adrian.test <- sqrt( res / length(test$outcome) )

tss <- sum((test$outcome - mean(test$outcome))^2)
r2.adrian.test <- 1 - (res/tss)
```


## Class Activity Local Regression

```{r}
data_diamond <- load('~/Downloads/cs112.RData')
right_order <- order(x1)
x <- x1[right_order]
y <- y1[right_order]
plot(x,y)

fit2.0 <- loess(y~x, span = 2, degree = 1) # fit the regression

fit1.0 <- loess(y~x, span = 1, degree = 1) # fit the regression
fit.5 <- loess(y~x, span = 0.5, degree = 1) # fit the regression
fit.4 <- loess(y~x, span = 0.4, degree = 1)
fit.35 <- loess(y~x, span = 0.35, degree = 1)
fit.3 <- loess(y~x, span = 0.3, degree = 1) # fit the regression
fit.2 <- loess(y~x, span = 0.2, degree = 1)
fit.25 <- loess(y~x, span = 0.25, degree = 1)
fit.1 <- loess(y~x, span = 0.1, degree = 1)
fit.05 <- loess(y~x, span = 0.05, degree = 1)

lines(x, predict(fit.35, x), lwd = 3, col = "red") # add lines to plot
lines(x, predict(fit.4, x), lwd = 3, col = "blue") # add lines to plot
lines(x, predict(fit.3, x), lwd = 3, col = "green")# add lines to plot
lines(x, predict(fit.25, x), lwd = 3, col = "black")
lines(x, predict(fit2.0, x), lwd = 3, col = "purple")


rmse1.0 <- sqrt( mean( (y - predict(fit1.0))^2 ) ) #calculate RMSE
rmse.5 <- sqrt( mean( (y - predict(fit.5))^2 ) ) # calculate RMSE
rmse.3 <- sqrt( mean( (y - predict(fit.3))^2 ) ) # calculate RMSE
rmse2.0 <- sqrt( mean( (y-predict(fit2.0))^2))
rmse.05 <- sqrt( mean( (y-predict(fit.05))^2))
rmse.35.train <- sqrt( mean( (y-predict(fit.35))^2))

rmse.35.train

test_data <- load('~/Downloads/cs112test.RData')
right_order <- order(x2)
x2 <- x2[right_order]
y2 <- y2[right_order]
plot(x,y)

rmse.5.test <- sqrt( mean( (y2-predict(fit.5))^2))
points(x2,y2, col="red")
rmse.35.test
```

